{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# APM598: Homework 3 (03/26)\n",
    "## author: Jieshu Wang (jwang490@asu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. n-gram models\n",
    "## Ex 1.\n",
    "### Ex 1. a) \n",
    "- Load and tokenize the text attached ’Plato_Republic.txt’.\n",
    "- Put all the words in lower case to regroup words like ’The’ and ’the’.\n",
    "- Compute the total number of words N in the text and the number of unique words (size of the vocabulary).\n",
    "    - size of vocabulary is ___7544___."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "the republic.     persons of the dialogue.  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with open('./data/Plato_Republic.txt', mode='r', encoding='utf-8-sig') as my_file:\n",
    "    # encoding='utf-8-sig' is to remove '\\ufeff' in the text.\n",
    "    my_text = my_file.read().replace('\\n',' ')\n",
    "    my_text = my_text.lower()\n",
    "\n",
    "print(my_text[0:44])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['the', 'republic', '.', 'persons', 'of', 'the', 'dialogue', '.', 'socrates', ',']\n",
      "-- length of texts (words) :  136312\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Tokenize words\n",
    "import nltk\n",
    "# nltk.data.path.append(\"/Users/Jieshu/PycharmProjects/APM598_Deep_Neural_Networks/APM598_notebook4/nltk_data\")\n",
    "\n",
    "my_text_tokenized = nltk.word_tokenize(my_text)\n",
    "print(my_text_tokenized[0:10])\n",
    "print(\"-- length of texts (words) : \",len(my_text_tokenized))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex 1. b) \n",
    "- Build a uni-gram. \n",
    "- Deduce the 5 most common words with at least 8 characters. \n",
    "    - 'certainly', 'knowledge', 'injustice', 'therefore', 'question'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The 5 most frequent words with at least 8 characters are:\n",
      "[('certainly', 235), ('knowledge', 152), ('injustice', 111), ('therefore', 109), ('question', 99)]\n",
      "The number of unique words are 7544\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# build a uni-gram\n",
    "my_unigram = nltk.ngrams(my_text_tokenized, 1)\n",
    "freq_dist_uni = nltk.FreqDist(my_unigram)\n",
    "\n",
    "# deduce the 5 most common words with at least 8 characters\n",
    "sorted_freq_dist_uni = freq_dist_uni.most_common()\n",
    "sorted_8_character_words = [(i[0][0], i[1]) for i in sorted_freq_dist_uni if len(i[0][0]) >=8]\n",
    "print(\"The 5 most frequent words with at least 8 characters are:\")\n",
    "print(sorted_8_character_words[0:5])\n",
    "print(f'The number of unique words are {freq_dist_uni.B()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex 1. c)\n",
    "- Build a bi-gram and define a function that given two words (x1, x2) compute the probability\n",
    ": $\\mathbb{P}(x_{t+1}|x_t) = \\frac{\\#\\{(x_t,x_{t+1})\\}}{\\#\\{(x_t)\\}\\}}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.032217308907138344\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "my_bigram = nltk.ngrams(my_text_tokenized, 2)\n",
    "# define a function to compute the probability\n",
    "def prob_word_pair(x_1: str, x_2: str, text) ->float:\n",
    "    corpus = nltk.word_tokenize(text.lower())\n",
    "    unigram = nltk.ngrams(corpus, 1)\n",
    "    bigram = nltk.ngrams(corpus, 2)\n",
    "    freq_distribution_uni = nltk.FreqDist(unigram)\n",
    "    freq_distribution_bi = nltk.FreqDist(bigram)\n",
    "    n_x_1 = freq_distribution_uni[(x_1.lower(),)]\n",
    "    n_x_1_2 = freq_distribution_bi[(x_1.lower(), x_2.lower())]\n",
    "    prob = n_x_1_2/n_x_1\n",
    "    return prob\n",
    "\n",
    "print(prob_word_pair('I', 'think', my_text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ex 1. d) \n",
    "- Deduce the so-called perplexity of the bi-gram model\n",
    "    - 37.89928782828084\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The perplexity of Plato's Republic is: \n",
      "37.89928782828084\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def compute_perplexity(text)->float:\n",
    "    corpus = nltk.word_tokenize(text.lower())\n",
    "    corpus_length = len(corpus)\n",
    "    unigram = nltk.ngrams(corpus, 1)\n",
    "    bigram = nltk.ngrams(corpus, 2)\n",
    "    freq_distribution_uni = nltk.FreqDist(unigram)\n",
    "    freq_distribution_bi = nltk.FreqDist(bigram)\n",
    "    product = 1\n",
    "    for i in range(corpus_length-1):\n",
    "        x_1 = corpus[i]\n",
    "        x_2 = corpus[i+1]\n",
    "        n_x_1 = freq_distribution_uni[(x_1.lower(),)]\n",
    "        n_x_1_2 = freq_distribution_bi[(x_1.lower(), x_2.lower())]\n",
    "        prob = n_x_1_2/n_x_1\n",
    "        product *= prob**(-1/(corpus_length-1))\n",
    "    perplexity = product\n",
    "    return  perplexity\n",
    "\n",
    "print(\"The perplexity of Plato's Republic is: \")\n",
    "print(compute_perplexity(my_text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Recurrent Neural Networks\n",
    "## Ex 2. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
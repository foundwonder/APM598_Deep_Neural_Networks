{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# APM598: Homework 3 (03/26)\n",
    "## author: Jieshu Wang (jwang490@asu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. n-gram models\n",
    "## Ex 1.\n",
    "### Ex 1. a) \n",
    "- Load and tokenize the text attached ’Plato_Republic.txt’.\n",
    "- Put all the words in lower case to regroup words like ’The’ and ’the’.\n",
    "- Compute the total number of words N in the text and the number of unique words (size of the vocabulary).\n",
    "    - size of vocabulary is ___7544___."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "the republic.     persons of the dialogue.  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with open('./data/Plato_Republic.txt', mode='r', encoding='utf-8-sig') as my_file:\n",
    "    # encoding='utf-8-sig' is to remove '\\ufeff' in the text.\n",
    "    my_text = my_file.read().replace('\\n',' ')\n",
    "    my_text = my_text.lower()\n",
    "\n",
    "print(my_text[0:44])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['the', 'republic', '.', 'persons', 'of', 'the', 'dialogue', '.', 'socrates', ',']\n",
      "-- length of texts (words) :  136312\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Tokenize words\n",
    "import nltk\n",
    "nltk.data.path.append(\"/Users/Jieshu/PycharmProjects/APM598_Deep_Neural_Networks/APM598_notebook4/nltk_data\")\n",
    "\n",
    "my_text_tokenized = nltk.word_tokenize(my_text)\n",
    "print(my_text_tokenized[0:10])\n",
    "print(\"-- length of texts (words) : \",len(my_text_tokenized))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex 1. b) \n",
    "- Build a uni-gram. \n",
    "- Deduce the 5 most common words with at least 8 characters. \n",
    "    - 'certainly', 'knowledge', 'injustice', 'therefore', 'question'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The 5 most frequent words with at least 8 characters are:\n",
      "[('certainly', 235), ('knowledge', 152), ('injustice', 111), ('therefore', 109), ('question', 99)]\n",
      "The number of unique words are 7544\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# build a uni-gram\n",
    "my_unigram = nltk.ngrams(my_text_tokenized, 1)\n",
    "freq_dist_uni = nltk.FreqDist(my_unigram)\n",
    "\n",
    "# deduce the 5 most common words with at least 8 characters\n",
    "sorted_freq_dist_uni = freq_dist_uni.most_common()\n",
    "sorted_8_character_words = [(i[0][0], i[1]) for i in sorted_freq_dist_uni if len(i[0][0]) >=8]\n",
    "print(\"The 5 most frequent words with at least 8 characters are:\")\n",
    "print(sorted_8_character_words[0:5])\n",
    "print(f'The number of unique words are {freq_dist_uni.B()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex 1. c)\n",
    "- Build a bi-gram and define a function that given two words (x1, x2) compute the probability\n",
    ": $\\mathbb{P}(x_{t+1}|x_t) = \\frac{\\#\\{(x_t,x_{t+1})\\}}{\\#\\{(x_t)\\}\\}}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.032217308907138344\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "my_bigram = nltk.ngrams(my_text_tokenized, 2)\n",
    "# define a function to compute the probability\n",
    "def prob_word_pair(x_1: str, x_2: str, text) ->float:\n",
    "    corpus = nltk.word_tokenize(text.lower())\n",
    "    unigram = nltk.ngrams(corpus, 1)\n",
    "    bigram = nltk.ngrams(corpus, 2)\n",
    "    freq_distribution_uni = nltk.FreqDist(unigram)\n",
    "    freq_distribution_bi = nltk.FreqDist(bigram)\n",
    "    n_x_1 = freq_distribution_uni[(x_1.lower(),)]\n",
    "    n_x_1_2 = freq_distribution_bi[(x_1.lower(), x_2.lower())]\n",
    "    prob = n_x_1_2/n_x_1\n",
    "    return prob\n",
    "\n",
    "print(prob_word_pair('I', 'think', my_text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ex 1. d) \n",
    "- Deduce the so-called perplexity of the bi-gram model\n",
    "    - 37.89928782828084\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The perplexity of Plato's Republic is: \n",
      "37.89928782828084\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def compute_perplexity(text)->float:\n",
    "    corpus = nltk.word_tokenize(text.lower())\n",
    "    corpus_length = len(corpus)\n",
    "    unigram = nltk.ngrams(corpus, 1)\n",
    "    bigram = nltk.ngrams(corpus, 2)\n",
    "    freq_distribution_uni = nltk.FreqDist(unigram)\n",
    "    freq_distribution_bi = nltk.FreqDist(bigram)\n",
    "    product = 1\n",
    "    for i in range(corpus_length-1):\n",
    "        x_1 = corpus[i]\n",
    "        x_2 = corpus[i+1]\n",
    "        n_x_1 = freq_distribution_uni[(x_1.lower(),)]\n",
    "        n_x_1_2 = freq_distribution_bi[(x_1.lower(), x_2.lower())]\n",
    "        prob = n_x_1_2/n_x_1\n",
    "        product *= prob**(-1/(corpus_length-1))\n",
    "    perplexity = product\n",
    "    return  perplexity\n",
    "\n",
    "print(\"The perplexity of Plato's Republic is: \")\n",
    "print(compute_perplexity(my_text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Recurrent Neural Networks\n",
    "## Ex 2. \n",
    "### Ex 2. a) find the output y1, . . . , y5 and deduce the predicted characters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "the output y1, . . . , y5 and deduce the predicted characters\n",
      "--- 0---\n",
      "    input: h\n",
      "    y_1: tensor([[ 1.5232,  1.1424, -0.7616, -0.3808]], grad_fn=<MmBackward>)\n",
      "    output: h\n",
      "--- 1---\n",
      "    input: e\n",
      "    y_2: tensor([[ 0.7087,  0.8257,  0.2340, -0.4713]], grad_fn=<MmBackward>)\n",
      "    output: e\n",
      "--- 2---\n",
      "    input: l\n",
      "    y_3: tensor([[-0.2096,  0.1031,  0.6255, -0.2079]], grad_fn=<MmBackward>)\n",
      "    output: l\n",
      "--- 3---\n",
      "    input: l\n",
      "    y_4: tensor([[-0.8934, -0.4887,  0.8095,  0.0420]], grad_fn=<MmBackward>)\n",
      "    output: l\n",
      "--- 4---\n",
      "    input: o\n",
      "    y_5: tensor([[-1.0946, -0.9446,  0.3000,  0.3973]], grad_fn=<MmBackward>)\n",
      "    output: o\n",
      "Predicted characters are: ['h', 'e', 'l', 'l', 'o']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from HW3_util import ModuleParamsVanillaRNN, VanillaRNN, letter_to_tensor, torch\n",
    "\n",
    "a_ex2a = torch.tensor([[1.0, -1.0, -0.5, 0.5],\n",
    "                       [1.0, 1.0, -0.5, -1]])\n",
    "r_ex2a = torch.tensor([[1.0, 0.0],\n",
    "                      [0.0, 1.0]])\n",
    "b_ex2a = torch.tensor([[1.0, 1.0],\n",
    "                       [0.5, 1.0],\n",
    "                       [-1.0, 0.0],\n",
    "                       [0.0, -0.5]])\n",
    "all_letters_ex2a = 'helo'\n",
    "input_letter_list = ['h', 'e', 'l', 'l', 'o']\n",
    "\n",
    "class VanillaRNNEx2a(VanillaRNN):\n",
    "    def __init__(self, module_params: ModuleParamsVanillaRNN):\n",
    "        super(VanillaRNNEx2a, self).__init__(module_params)\n",
    "        with torch.no_grad():\n",
    "            self._A.weight.data = a_ex2a\n",
    "            self._R.weight.data = r_ex2a\n",
    "            self._B.weight.data = b_ex2a\n",
    "\n",
    "def predict_characters_ex2a(input_list: list, all_letters: str):\n",
    "    vanilla_rnn_params = ModuleParamsVanillaRNN(all_letters_base=all_letters)\n",
    "    my_vanilla_rnn_ex2a = VanillaRNNEx2a(vanilla_rnn_params)\n",
    "    h = my_vanilla_rnn_ex2a.init_hidden()\n",
    "    predicted_charaters_list = []\n",
    "    for i in range(len(input_list)):\n",
    "        input = input_list[i]\n",
    "        print(f'--- {i}---')\n",
    "        x = letter_to_tensor(input, all_letters)\n",
    "        y, h = my_vanilla_rnn_ex2a(x, h)\n",
    "        predicted_character = all_letters[y.argmax()]\n",
    "        print(f\"    input: {input}\")\n",
    "        print(f'    y_{i+1}: {y}')\n",
    "        print(f'    output: {predicted_character}')\n",
    "        predicted_charaters_list.append(predicted_character)\n",
    "    print(f'Predicted characters are: {predicted_charaters_list}')\n",
    "\n",
    "print('the output y1, . . . , y5 and deduce the predicted characters')\n",
    "predict_characters_ex2a(input_letter_list, all_letters_ex2a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex 2. b) Find matrices A, R, B such that the predicted characters are ”olleh”.\n",
    "- A.weight: [[-1.6251, -0.6183,  0.7184,  1.0523], [-1.5250, -0.3831,  1.4286, -0.9764]]\n",
    "- R.weight: [[ 2.6304,  1.8039], [-1.3376, -0.0809]]\n",
    "- B.weight: [[ 2.6276, -1.8918], [ 2.9543,  2.2045], [-2.1664,  2.6917], [-1.7653, -2.3543]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "  input = hello\n",
      "  output = elell\n",
      "loss at step 0: 1.3737117767333984\n",
      "  input = hello\n",
      "  output = olllh\n",
      "loss at step 60: 1.2573498725891112\n",
      "  input = hello\n",
      "  output = olllh\n",
      "loss at step 120: 1.0862698554992676\n",
      "  input = hello\n",
      "  output = olllh\n",
      "loss at step 180: 0.9848179817199707\n",
      "  input = hello\n",
      "  output = olllh\n",
      "loss at step 240: 0.9285406112670899\n",
      "  input = hello\n",
      "  output = olleh\n",
      "loss at step 300: 0.8724645614624024\n",
      "  input = hello\n",
      "  output = olleh\n",
      "loss at step 360: 0.8253401756286621\n",
      "  input = hello\n",
      "  output = olleh\n",
      "loss at step 420: 0.8008445739746094\n",
      "  input = hello\n",
      "  output = olleh\n",
      "loss at step 480: 0.7867999076843262\n",
      "  input = hello\n",
      "  output = olleh\n",
      "loss at step 540: 0.7776077270507813\n",
      "<generator object Module.parameters at 0x10511ad50>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from HW3_util import VanillaRNNTrainer, VanillaRNN, ModuleParamsVanillaRNN\n",
    "\n",
    "all_letters_ex2b = 'helo'\n",
    "training_x_ex2b = 'hello'\n",
    "training_y_ex2b = 'olleh'\n",
    "module_params_ex2b = ModuleParamsVanillaRNN(all_letters_base=all_letters_ex2b, chunk_size=5,\n",
    "                                            is_print_training=True, n_steps=600, printing_step=60)\n",
    "trainer_ex2b = VanillaRNNTrainer(module_params=module_params_ex2b, module=VanillaRNN,\n",
    "                                 training_x=training_x_ex2b, training_y=training_y_ex2b)\n",
    "print(trainer_ex2b.model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "_A.weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4536, -0.5005, -0.9105,  1.1894],\n",
      "        [-1.7484, -0.7461,  0.5157,  1.1955]], requires_grad=True)\n",
      "_R.weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.0282,  1.6511],\n",
      "        [-1.5973,  2.2827]], requires_grad=True)\n",
      "_B.weight\n",
      "Parameter containing:\n",
      "tensor([[ 2.5070,  2.3268],\n",
      "        [-1.8582,  2.4097],\n",
      "        [-2.5935, -2.4388],\n",
      "        [ 2.4732, -1.9732]], requires_grad=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "result_model_parameters = trainer_ex2b.model.named_parameters()\n",
    "for name, params in result_model_parameters:\n",
    "    print(f'{name}')\n",
    "    print(f'{params}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ex 3. vanishing/exploding gradient\n",
    "### Ex 3 a) \n",
    "### Ex 3 b) compute and plot the difference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The difference is \n",
      "              perturbation  perturbation_log  y_difference  y_difference_log\n",
      "1.000000e-04  1.000000e-04              -4.0      1.213693          0.084109\n",
      "1.000000e-05  1.000000e-05              -5.0      1.128870          0.052644\n",
      "1.000000e-06  1.000000e-06              -6.0      0.265372         -0.576146\n",
      "1.000000e-07  1.000000e-07              -7.0      0.027112         -1.566843\n",
      "1.000000e-08  1.000000e-08              -8.0      0.002712         -2.566748\n",
      "1.000000e-09  1.000000e-09              -9.0      0.000271         -3.566747\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from HW3_util import ModuleParamsVanillaRNN, VanillaRNN, letter_to_tensor, torch, compute_y_difference\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a_ex3b = torch.tensor([[1.0, 0.0],\n",
    "                       [0.0, 1.0]])\n",
    "r_ex3b = torch.tensor([[0.5, -1.0],\n",
    "                      [-1.0, 0.5]])\n",
    "b_ex3b = torch.tensor([[1.0, 0.0],\n",
    "                       [0.0, 1.0]])\n",
    "perturbation_values_ex3 = [10**(-i) for i in range(4, 10)]\n",
    "all_letters_ex3b = 'ab'\n",
    "\n",
    "class VanillaRNNEx3b(VanillaRNN):\n",
    "    def __init__(self, module_params: ModuleParamsVanillaRNN):\n",
    "        super(VanillaRNNEx3b, self).__init__(module_params)\n",
    "        self._in_out_size = 2\n",
    "        self._hidden_size = 2\n",
    "        with torch.no_grad():\n",
    "            self._A.weight.data = a_ex3b\n",
    "            self._R.weight.data = r_ex3b\n",
    "            self._B.weight.data = b_ex3b\n",
    "\n",
    "module_params_ex3b = ModuleParamsVanillaRNN(all_letters_base=all_letters_ex3b)\n",
    "\n",
    "def pertubating_x_ex3b(perturbation):\n",
    "    return torch.tensor([perturbation, -perturbation])\n",
    "\n",
    "x_1_ex3b = torch.tensor([0.0, 0.0])\n",
    "x_n_ex3b = torch.tensor([0.0, 0.0])\n",
    "h_n_ex3b = torch.tensor([0.0, 0.0])\n",
    "df_ex3b = compute_y_difference(num_times=30, x_1=x_1_ex3b, x_n=x_n_ex3b, h_0=h_n_ex3b,\n",
    "                               perturbating_func=pertubating_x_ex3b, \n",
    "                               perturbation_values=perturbation_values_ex3,\n",
    "                               module=VanillaRNNEx3b, module_params=module_params_ex3b)\n",
    "print(f'The difference is \\n{df_ex3b}')\n",
    "\n",
    "# plot log-log scale\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(df_ex3b['perturbation_log'], df_ex3b['y_difference_log'], '-o')\n",
    "plt.grid()\n",
    "plt.xlabel('log of perturbations')\n",
    "plt.ylabel('log of norm of y difference')\n",
    "plt.title(\"Difference of y per perturbation\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex 3c) Proceedsimilarlyasb)usingx1 =(2,1)andx1ε =(2+ε,1−ε).\n",
    "Why does the perturbation have a small effect in this case compare to b)?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The difference is \n",
      "              perturbation  perturbation_log  y_difference y_difference_log\n",
      "1.000000e-04  1.000000e-04              -4.0           0.0               -∞\n",
      "1.000000e-05  1.000000e-05              -5.0           0.0               -∞\n",
      "1.000000e-06  1.000000e-06              -6.0           0.0               -∞\n",
      "1.000000e-07  1.000000e-07              -7.0           0.0               -∞\n",
      "1.000000e-08  1.000000e-08              -8.0           0.0               -∞\n",
      "1.000000e-09  1.000000e-09              -9.0           0.0               -∞\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZwcVb338c83CUvYEhAYICFEQsCLCwgDiIAMO/iIcCXIdpUoEPFx9xEIghARLotL5L5cMEJkcQFBlqAoFwgDgmyJLAEUw2oSFglZYGLYwu/5o85A0/R0amqmu6fT3/fr1a+pOnWq6ne6e/rX51R1lSICMzOz3hrU6ADMzKw5OYGYmVkhTiBmZlaIE4iZmRXiBGJmZoU4gZiZWSFOINYrks6T9K2S+c9Lek5Sl6R3SdpJ0uw0f2AjY60VSadLmi/p2UbH0owkhaTN+mlbo9J7bXB/bM96R/4diHWT9CTQBrwOLAMeBi4GpkTEGxXqrwS8CHwoIu5PZTcB0yLi3HrFXU+SRgGPAJtExL8aHU89SRoPHB0RO/dxOwGMjYhHC6z7ZIrhxr7EYP3DPRArt39ErAlsApwFnABc0EPdNmBV4KGSsk3K5nOTNKTIenU2CnhhoCWPWj93/bH9Jnl9rTciwg8/iAiAJ4E9y8q2B94A3pfmLwROBzYHlgABdAHTgcdS3aWpbBVgGFkCegaYl9YdnLY1HrgdmAy8AJyeyj8L/A1YCFxP9m2/O54AjgVmA4uAH5N60mn5MWndl8h6UNuk8o2A3wHPA08AX67yPAwj63k9DzwFnEz2ZWvP1LY3UvsurLDug2RJuHt+JWA+8MEKdTuAucA3U50ngSNKlq8CfA/4J/AccB4wtGzdE4BngUsqbL/7+f0RsBj4O7BHWTvzvja/A14m65l2AYtSvU6yHkHpPm8re72+kF6vJ0rKvgw8ntr9XWBQWjaG7L30Qlr2K2B4WnYJb39/HQ+MTtsbUvI6TwMWAI8Cx5TEMgn4bXptXyL7otPe6P+7Zn40PAA/Bs6DCgkklf8T+HyavpC3Pujf9s9baRvAVcDPgNWB9YG7gc+lZePJhsu+BAwBhgIHpH/8/0hlJwN/KdleAL8HhpP1Bp4H9k3LDk4fhNsBAjYj6xENAmYCpwArA5umD699engeLgauAdZMbfwHcFRa1gHMrfIcHg9cVjJ/ADCrh7odqf0/IEsWu5Il5S3S8snpw3CdFMu1wJll656d1h1aYfvdz+/XyBLZIWSJZJ2Cr814SpJDqtfJ8hPIDakNQ0vKbk5lo9Lze3RathmwV2rTesCtwA+rvL9G8/YEcivwE7Ke8dbp/bF7WjaJLAl+FBgMnAnc2ej/u2Z+NDwAPwbOo/yfs6T8TuCkNH0hORMI2RDXK6UfbsBhwM1pejzwz7J9/ZH0YZ3mBwH/JvVC0v52Lln+W2Bimr4e+EqF+HeosJ8TgV9UqDsYeBXYsqTsc0Bnmu6gegLZiOzb7Vpp/grg+B7qdpB9SK9e1p5vkSXAJcCYkmU78ta3+I4U56pVYhkPPM3be2h3A58q+NqMp1gC2b1snSAl/TT/f4GbemjDgcC9Pb1HS9+DwMZkPaQ1S5afSeopkiWQG0uWbQksbeT/XLM/PCZpeYwgGxLorU3Ivvk+I6m7bBAwp6TOnArrnCvp+yVlSjE8leZLz376N7BGmt6YbBitUhwbSVpUUjYY+HOFuuummJ8qKXsq7X+5IuJpSbcDB0m6CtgP+EqVVRZGxJKyfW1E9u17NWBmyXOnFHe35yPi5eWENC/Sp2XZ9ou8NkVV2k5pWXdMSGoDzgV2Iet1DSIbysxjI2BBRLxUtu32kvny986qkoZExOs592ElnECsKknbkX143lZg9Tlk33LXrfIPWn4a4BzgjIj4VcH9jemh/ImIGJtjG/OB18g+YB9OZaPIhsbyugg4muz/646IqLbu2pJWL0kio8iOo8wnG+t/b5X185xCOUKSSpLIKLJhsSKvTaX9LSFLdN02yBnnxrx1ssUosp4SwH+n+u+PiAXpVPAfLWdb3Z4G1pG0ZkkS6e1rZ73gs7CsIklrSfoYcCnwy4iY1dttRMQzwP8C30/bGyRpjKRdq6x2HnCipPemOIZJOjjnLs8HviFpW2U2k7QJ2bDNS5JOkDRU0mBJ70vJsTzmZWTDSGdIWjOt/3Xgl/lbztXANmQ9j4tz1P+2pJUl7QJ8DLg8stOmfw5MlrQ+gKQRkvbpRRyQHdv4sqSV0vP4H8B1BV+b54CRklYuKbsP+ISk1dJvO47KGddxktaWtDHZ83RZKl+T7AD5YkkjgOMqxLBppQ1GxBzgL8CZklaV9IEUT29eO+sFJxArd62kl8i+oZ5EdoD3M33Y3qfJDlw/TDYUcQWwYU+VI+IqsgPDl0p6kezb+H55dhQRlwNnAL8mOw5xNdkB42VkH8xbk52BNZ8s2QzrYVNfIvtm/ThZz+vXwNQ8MaQ4lpKdtfRu4MrlVH+W7Hl5muyMo2Mj4u9p2QlkJxTcmZ6LG4Et8saR3AWMJWvzGcC4iHghLevVa0N2dtRDwLOS5qeyyWTHYp4j63nl7TleQ3Ziw33AH3jrVPFvkyXfxam8/Pk7EzhZ0iJJ36iw3cPIjos8TXaSwKnh34zUjH9IaFYDkk4BNo+I/6pSp4OsdzeyRjGMpx9++GfWEx8DMetnktYhGzr5VKNjMaslD2GZ9SNJx5AN//0xIm5tdDxmteQhLDMzK8Q9EDMzK6SljoGsu+66MXr06ELrLlmyhNVXX71/Axrg3ObW0GptbrX2Qt/bPHPmzPkRsV55eUslkNGjRzNjxoxC63Z2dtLR0dG/AQ1wbnNraLU2t1p7oe9tlvRUpXIPYZmZWSFOIGZmVogTiJmZFeIEYmZmhTiBmJlZIU4gZmZWiBOImZkV4gRiZmaFOIGYmVkhTiBmZlaIE4iZmRXiBGJmZoU4gZiZWSFOIGZmVogTiJmZFeIEYmZmhTiBmJlZIU4gZmZWiBOImZkV4gRiZmaFOIGYmVkhTiBmZlaIE4iZmRXiBGJmZoU4gZiZWSENTSCS9pX0iKRHJU2ssHwVSZel5XdJGl22fJSkLknfqFfMZmaWaVgCkTQY+DGwH7AlcJikLcuqHQUsjIjNgMnA2WXLfwD8sdaxmpnZOzWyB7I98GhEPB4RrwKXAgeU1TkAuChNXwHsIUkAkg4EngAeqlO8ZmZWYkgD9z0CmFMyPxfYoac6EfG6pMXAuyS9DJwA7AVUHb6SNAGYANDW1kZnZ2ehYLu6ugqv26zc5tbQam1utfZC7drcyATSF5OAyRHRlTokPYqIKcAUgPb29ujo6Ci0w87OToqu26zc5tbQam1utfZC7drcyAQyD9i4ZH5kKqtUZ66kIcAw4AWynso4SecAw4E3JL0cET+qfdhmZgaNTSD3AGMlvZssURwKHF5WZxpwJHAHMA6YHhEB7NJdQdIkoMvJw8ysvhqWQNIxjS8C1wODgakR8ZCk04AZETENuAC4RNKjwAKyJGNmZgNAQ4+BRMR1wHVlZaeUTL8MHLycbUyqSXBmZlaVf4luZmaFOIGYmVkhTiBmZlaIE4iZmRXiBGJmZoU4gZiZWSFOIGZmVogTiJmZFeIEYmZmhTiBmJlZIU4gZmZWiBOImZkV4gRiZmaFOIGYmVkhTiBmZlaIE4iZmRXiBGJmZoU4gZiZWSFOIGZmVogTiJmZFeIEYmZmhTiBmJlZIU4gZmZWiBOImZkVkiuBSNpE0p5peqikNWsblpmZDXTLTSCSjgGuAH6WikYCV9cyKDMzG/jy9EC+AOwEvAgQEbOB9WsZlJmZDXx5EsgrEfFq94ykIUDULiQzM2sGeRLILZK+CQyVtBdwOXBtbcMyM7OBLk8CmQg8D8wCPgdcB5xcy6DMzGzgy5NAhgJTI+LgiBgHTE1lfSZpX0mPSHpU0sQKy1eRdFlafpek0al8L0kzJc1Kf3fvj3jMzCy/PAnkJt6eMIYCN/Z1x5IGAz8G9gO2BA6TtGVZtaOAhRGxGTAZODuVzwf2j4j3A0cCl/Q1HjMz6508CWTViOjqnknTq/XDvrcHHo2Ix9NB+kuBA8rqHABclKavAPaQpIi4NyKeTuUPkR2fWaUfYjIzs5zyJJAlkrbpnpG0LbC0H/Y9AphTMj83lVWsExGvA4uBd5XVOQj4a0S80g8xmZlZTkNy1PkqcLmkpwEBGwCH1DSqnCS9l2xYa+8qdSYAEwDa2tro7OwstK+urq7C6zYrt7k1tFqbW629ULs2LzeBRMQ9kt4DbJGKHomI1/ph3/OAjUvmR6aySnXmpt+fDANeAJA0ErgK+HREPFYl/inAFID29vbo6OgoFGxnZydF121WbnNraLU2t1p7oXZtztMDAdgOGJ3qbyOJiLi4j/u+Bxgr6d1kieJQ4PCyOtPIDpLfAYwDpkdESBoO/AGYGBG39zEOMzMrYLkJRNIlwBjgPmBZKg6gTwkkIl6X9EXgemAw2anCD0k6DZgREdOAC4BLJD0KLCBLMgBfBDYDTpF0SirbOyL+1ZeYzMwsvzw9kHZgy4jo98uXRMR1ZD9MLC07pWT6ZeDgCuudDpze3/GYmVl+ec7CepDswLmZmdmb8vRA1gUelnQ38OapshHx8ZpFZWZmA16eBDKp1kGYmVnzyXMa7y2SNgHGRsSNklYjO+htZmYtrMgdCUfgOxKambU835HQzMwK8R0JzcysEN+R0MzMCvEdCc3MrJCqZ2Glmz5dHBFHAD+vT0hmZtYMqvZAImIZsImklesUj5mZNYk8PyR8HLhd0jRgSXdhRPygZlGZmdmAlyeBPJYeg4A1axuOmZk1izy/RP82gKTVIuLftQ/JzMyaQZ5fou8o6WHg72l+K0k/qXlkZmY2oOU5jfeHwD6kW8lGxP3AR2oZlJmZDXx5EggRMaesaFnFimZm1jLyHESfI+nDQEhaCfgK8LfahmVmZgNdnh7IsWQXVBwBzAO2TvNmZtbCeuyBSDo7Ik4Adku/RDczM3tTtR7IRyUJOLFewZiZWfOodgzkT8BCYA1JLwIiu4y7gIiIteoQn5mZDVDVeiAnR8Rw4A8RsVZErFn6t14BmpnZwFQtgdyR/r5Yj0DMzKy5VBvCWlnS4cCHJX2ifGFEXFm7sMzMbKCrlkCOBY4AhgP7ly0LwAnEzKyF9ZhAIuI24DZJMyLigjrGZGZmTaDa70B2j4jpwEIPYZmZWblqQ1i7AtN55/AVeAjLzKzlVRvCOjX9/Uz9wjEzs2ZRbQjr69VW9C1tzcxaW7XfgayZHu3A58kupjiC7Oysbfpj55L2lfSIpEclTaywfBVJl6Xld0kaXbLsxFT+iKR9+iOeSq6+dx47nTWd8X9awk5nTefqe+fValcDhtvsNq+IWq29UPs2VxvC6r6V7a3ANhHxUpqfBPyhrzuWNBj4MbAXMBe4R9K0iHi4pNpRwMKI2EzSocDZwCGStgQOBd4LbATcKGnziOjX+5Rcfe88TrxyFktfyzY7b9FSTrxyFgAHfnBEf+5qwHCb3eYVsc2t1l6oT5sVEdUrSI8AH4iIV9L8KsADEbFFn3Ys7QhMioh90vyJABFxZkmd61OdOyQNAZ4F1gMmltYtrVdtn+3t7TFjxozcMe501nTmLVr6jvKVBw/ig6OG595OM7n3n4t4ddkb7yh3m1csrdbmVmsv9NzmEcOHcvvE3Xu1LUkzI6K9vDzPDaUuBu6WdFWaPxC4sFd7r2wEUHqnw7nADj3ViYjXJS0G3pXK7yxbt2JKlTQBmADQ1tZGZ2dn7gArJQ+AV5e9waJFi3Jvp5lUesN1l7vNK45Wa3OrtRd6bvO8RUt79TlYzXITSEScIemPwC6p6DMRcW+/7L0OImIKMAWyHkhHR0fudUfcWbkHMmL4UK4/oXcZvFn01Otym1csrdbmVmsvVG9zbz4Hq8l7T/S/RsS56dFfyWMesHHJ/MhUVrFOGsIaBryQc90+O26fLRi60uC3lQ1daTDH7dOn0bsBzW3OuM0rllZrL9SnzXmGsGrlHmCspHeTffgfChxeVmcacCTZlYHHAdMjIiRNA34t6QdkB9HHAnf3d4DdB5q+e/0jzFu0lBHDh3LcPlussAfdwG12m1fMNrdae6FObY6Ihj2AjwL/AB4DTkplpwEfT9OrApcDj5IliE1L1j0prfcIsF+e/W277bZR1M0331x43WblNreGVmtzq7U3ou9tBmZEhc/U5fZAJH0J+GVELOy/tJWJiOuA68rKTimZfhk4uId1zwDO6O+YzMwsnzzHQNrIfqPx2/TDP9U6KDMzG/iWm0Ai4mSyYwwXAOOB2ZL+W9KYGsdmZmYDWN6zsILsR3zPAq8DawNXSDqnhrGZmdkAlucYyFeATwPzgfOB4yLiNUmDgNnA8bUN0czMBqI8p/GuA3wiIp4qLYyINyR9rDZhmZnZQJfnl+inVln2t/4Nx8zMmkWuYyBmZmblekwg6aq7ZmZmFVXrgdwBIOmSOsViZmZNpNoxkJUlHQ58WNInyhdGxJW1C8vMzAa6agnkWOAIYDiwf9myAJxAzMxaWLVb2t4G3CZpRkRcUMeYzMysCeT5Hcglkr4MfCTN3wKcFxGv1S4sMzMb6PIkkJ8AK6W/AJ8CfgocXaugzMxs4MuTQLaLiK1K5qdLur9WAZmZWXPI80PCZaVX3pW0KbCsdiGZmVkzyNMDOQ64WdLjgIBNgM/UNCozMxvw8lwL6yZJY4HuO7E/EhGv1DYsMzMb6PL0QEgJ44Eax2JmZk3EF1M0M7NCnEDMzKyQXENYkj4AjC6t72thmZm1tjy3tJ0KfAB4CHgjFftaWGZmLS5PD+RDEbFlzSMxM7OmkucYyB2SnEDMzOxt8vRALiZLIs8Cr5D9mDAi4gM1jczMzAa0PAnkArILKM7irWMgZmbW4vIkkOcjYlrNIzEzs6aSJ4HcK+nXwLVkQ1iAT+M1M2t1eRLIULLEsXdJmU/jNTNrcVUTiKTBwAMRMbk/dyppHeAysh8nPgl8MiIWVqh3JHBymj09Ii6StBpwOTCG7LLy10bExP6Mz8zMlq/qabwRsQw4rAb7nQjcFBFjgZvS/NukJHMqsAOwPXCqpLXT4u9FxHuADwI7SdqvBjGamVkVeX4HcrukH0naRdI23Y8+7vcA4KI0fRFwYIU6+wA3RMSC1Du5Adg3Iv4dETcDRMSrwF+BkX2Mx8zMeinPMZCt09/TSsoC2L0P+22LiGfS9LNAW4U6I4A5JfNzU9mbJA0H9gfO7UMsZmZWQJ4bSu1WZMOSbgQ2qLDopLLth6QosP0hwG+A/4mIx6vUmwBMAGhra6Ozs7O3uwKgq6ur8LrNym1uDa3W5lZrL9SuzXkupjiM7FjER1LRLcBpEbG42noRsWeVbT4nacOIeEbShsC/KlSbB3SUzI8EOkvmpwCzI+KHy4ljSqpLe3t7dHR0VKveo87OToqu26zc5tbQam1utfZC7dqc5xjIVOAl4JPp8SLwiz7udxpwZJo+ErimQp3rgb0lrZ0Onu+dypB0OjAM+Gof4zAzs4LyJJAxEXFqRDyeHt8GNu3jfs8C9pI0G9gzzSOpXdL5ABGxAPgOcE96nBYRCySNJBsG2xL4q6T7JB3dx3jMzKyX8hxEXypp54i4DUDSTsDSvuw0Il4A9qhQPgM4umR+KlkPqLTOXLILOpqZWQPlSSDHAhenYyECFgDjaxmUmZkNfHnOwrof2ErSWmn+xZpHZWZmA16es7BWAQ4i3RNdykaPIuK0KquZmdkKLs8Q1jXAYmAmJVfjNTOz1pYngYyMiH1rHomZmTWVPKfx/kXS+2seiZmZNZU8PZCdgfGSnsD3RDczsyRPAvGl0s3M7B3ynMb7VD0CMTOz5pLnGIiZmdk7OIGYmVkhTiBmZlaIE4iZmRXiBGJmZoU4gZiZWSFOIGZmVogTiJmZFeIEYmZmhTiBmJlZIU4gZmZWiBOImZkV4gRiZmaFOIGYmVkhTiBmZlaIE4iZmRXiBGJmZoU4gZiZWSFOIGZmVogTiJmZFeIEYmZmhTiBmJlZIQ1JIJLWkXSDpNnp79o91Dsy1Zkt6cgKy6dJerD2EZuZWblG9UAmAjdFxFjgpjT/NpLWAU4FdgC2B04tTTSSPgF01SdcMzMr16gEcgBwUZq+CDiwQp19gBsiYkFELARuAPYFkLQG8HXg9DrEamZmFSgi6r9TaVFEDE/TAhZ2z5fU+QawakScnua/BSyNiO9JmgzcCtwL/D4i3ldlXxOACQBtbW3bXnrppYVi7urqYo011ii0brNym1tDq7W51doLfW/zbrvtNjMi2svLh/Qpqiok3QhsUGHRSaUzERGScmcxSVsDYyLia5JGL69+REwBpgC0t7dHR0dH3l29TWdnJ0XXbVZuc2totTa3Wnuhdm2uWQKJiD17WibpOUkbRsQzkjYE/lWh2jygo2R+JNAJ7Ai0S3qSLP71JXVGRAdmZlY3jToGMg3oPqvqSOCaCnWuB/aWtHY6eL43cH1E/DQiNoqI0cDOwD+cPMzM6q9RCeQsYC9Js4E90zyS2iWdDxARC4DvAPekx2mpzMzMBoCaDWFVExEvAHtUKJ8BHF0yPxWYWmU7TwI9HkA3M7Pa8S/RzcysECcQMzMrxAnEzMwKcQIxM7NCnEDMzKwQJxAzMyvECcTMzApxAjEzs0KcQMzMrBAnEDMzK8QJxMzMCnECMTOzQpxAzMysECcQMzMrxAnEzMwKcQIxM7NCnEDMzKwQJxAzMyvECcTMzApxAjEzs0KcQMzMrBAnEDMzK8QJxMzMCnECMTOzQhQRjY6hbiQ9DzxVcPV1gfn9GE4zcJtbQ6u1udXaC31v8yYRsV55YUslkL6QNCMi2hsdRz25za2h1drcau2F2rXZQ1hmZlaIE4iZmRXiBJLflEYH0ABuc2totTa3WnuhRm32MRAzMyvEPRAzMyvECcTMzApxAukFSVtJukPSLEnXSlqr0THVmqStJd0p6T5JMyRt3+iYaknSZamt90l6UtJ9jY6pHiR9SdLfJT0k6ZxGx1NrkiZJmlfyWn+00THVi6T/JykkrdvXbQ3pj4BayPnANyLiFkmfBY4DvtXgmGrtHODbEfHH9E92DtDR2JBqJyIO6Z6W9H1gcQPDqQtJuwEHAFtFxCuS1m90THUyOSK+1+gg6knSxsDewD/7Y3vugfTO5sCtafoG4KAGxlIvAXT3tIYBTzcwlrqRJOCTwG8aHUsdfB44KyJeAYiIfzU4HqudycDxZP/XfeYE0jsPkX1TAzgY2LiBsdTLV4HvSpoDfA84scHx1MsuwHMRMbvRgdTB5sAuku6SdIuk7RodUJ18UdIDkqZKWrvRwdSapAOAeRFxf39t00NYZSTdCGxQYdFJwGeB/5H0LWAa8Go9Y6uV5bR5D+BrEfE7SZ8ELgD2rGd8/a1aeyPimjR9GCtQ72M5r/EQYB3gQ8B2wG8lbRpNfo7/ctr8U+A7ZN/EvwN8n+z/u6ktp83fJBu+6r/9Nfl7pGEkbQ78MiJW9IPKi4HhERFpWGdxRKzQJw9IGgLMA7aNiLmNjqfWJP0JODsibk7zjwEfiojnGxtZfUgaDfw+It7X4FBqRtL7gZuAf6eikWTD0dtHxLNFt+shrF7oPrgoaRBwMnBeYyOqi6eBXdP07kArDOnsCfy9FZJHcjWwG7z5xWhlVvCr1UrasGT2P4EHGxVLPUTErIhYPyJGR8RoYC6wTV+SB3gIq7cOk/SFNH0l8ItGBlMnxwDnpm/lLwMTGhxPPRzKCjR8lcNUYKqkB8mGZY9s9uGrHM6RtDXZENaTwOcaG05z8hCWmZkV4iEsMzMrxAnEzMwKcQIxM7NCnEDMzKwQJxAzMyvECcRWCJK6arz996Srtt4raUw/b7tD0ocLrDc6nXrbm3XGS9qoZP58SVv2dt9m4ARilteBwBUR8cGIeKy/Npp+X9MB9CqBpPWKGA+8mUAi4uiIeLjgtqzFOYHYCkWZ70p6MN235ZBUPkjST9I9L26QdJ2kcRXW777/yQOSrpK0drqM/VeBz0u6ucI6XZImp3tp3CRpvVQ+RtKfJM2U9GdJ70nlF0o6T9JdwG+BY4GvpR7OLmn5uNLtp78daTvTgO4P/SGSfiXpb5KukLRaqnuKpHvS8zAlPS/jgHbgV2lfQyV1SmpP6xyWnrMHJZ1d1r4zJN2fnpu2VH5wqnu/pO6rVFsriQg//Gj6B9CV/h5Edqn9wUAb2X0PNgTGAdeRfWnaAFgIjKuwnQeAXdP0acAP0/QksnvBVNp3AEek6VOAH6Xpm4CxaXoHYHqavhD4PTC40rbT8nEV2tYBLAHeneZHp33vlOandm8HWKdk/UuA/dN0J9BesqyTLKlslJ6r9ciuUDEdOLCkfd3rnwOcnKZnASPS9PBGvwf8qP/DPRBb0ewM/CYilkXEc8AtZFeY3Rm4PCLeiOz6P5V6EsPIPghvSUUXAR/Jsc83gMvS9C+BnSWtQTYsdbmyuxr+jCyRdbs8Ipb1vnncHRFPlMzPiYjbS/edpndLl2efRXYNs/cuZ7vbAZ0R8XxEvA78irfa/ipZwgOYSZa4AG4HLpR0DFnCthbja2GZ9b8g6+ksioite6izpMr6r6f1uy/cuXKV9cqvRRSSVgV+QtbTmCNpErBqztgreS0iuvezjPS5ERHHStoB+D/ATEnbRsQLfdiPNRn3QGxF82fgEEmD07GIjwB3k31bPigdC2mjwm15I2IxsFDSLqnoU2Q9mOUZRDZEBnA4cFtEvAg8IelgePPYzFY9rP8SsGbJ/JPAtmn648BKVfY9StKOpfvmrWQxP/WESo/1lO+r293ArpLWlTSY7H4oVdsuaUxE3BURpwDP0xo3WLMSTiC2ormK7DjG/WTj+MenIavfkV3C+mGyoZ6/Uvl+50eS3YHxAWBrsuMgy7ME2D6dUrt7yTpHAEdJup+3382y3LXAf3YfRAd+TvZhfj+wI9V7K48AX5D0N2Bt4KcRsSht40HgeuCekvoXAud1H0TvLoyIZ4CJZEN79wMz462ba/Xku90H3YG/pPWshfhqvNYyJK0REV2S3kX2jXun6OP9ENJ2uyJijSOdS6EAAABBSURBVL5HaNZcfAzEWsnvJQ0nO6bwnf5IHmatzD0QMzMrxMdAzMysECcQMzMrxAnEzMwKcQIxM7NCnEDMzKyQ/w83yyNiqxjRsgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from HW3_util import compute_y_difference, torch\n",
    "\n",
    "def pertubating_x_ex3c(perturbation):\n",
    "    return torch.tensor([2.0+perturbation, 1.0-perturbation])\n",
    "\n",
    "x_1_ex3c = torch.tensor([2.0, 1.0])\n",
    "x_n_ex3c = torch.tensor([0.0, 0.0])\n",
    "h_n_ex3c = torch.tensor([0.0, 0.0])\n",
    "\n",
    "df_ex3c = compute_y_difference(30, x_1_ex3c, x_n_ex3c, h_n_ex3c, pertubating_x_ex3c, perturbation_values_ex3, \n",
    "                               VanillaRNNEx3b, module_params_ex3b, precision=10)\n",
    "print(f'The difference is \\n{df_ex3c}')\n",
    "\n",
    "# plot log-log scale\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(df_ex3c['perturbation_log'], df_ex3c['y_difference'], '-o')\n",
    "plt.grid()\n",
    "plt.xlabel('log of perturbations')\n",
    "plt.ylabel('norm of y difference')\n",
    "plt.title(\"Difference of y per perturbation\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}